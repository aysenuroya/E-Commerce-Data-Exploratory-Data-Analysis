{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\nfrom scipy import stats \n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/ecommerce-data/data.csv\", encoding=\"ISO-8859-1\", dtype={'CustomerID': str})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all').T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Missing Values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns[data.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_missings=data.filter(['Description', 'CustomerID'], axis=1)\nmsno.bar(data_missings);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.heatmap(data); ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def values_table(data_missings):\n    mis_val = data_missings.isnull().sum()\n    mis_val_percent = 100 * data_missings.isnull().sum() / len(data_missings)\n    table = pd.concat([ mis_val,mis_val_percent], axis=1)\n    table = table.rename(columns = {  0 :'Missing Values', 1 : '% Missing Value'})\n    table['Data Type'] = data_missings.dtypes\n    table = table[table.iloc[:,1] != 0].sort_values('% Missing Value', ascending=False).round(1)\n    print (\"There are \" + str(data.shape[1]) + \" columns and \" + str(data.shape[0]) + \" rows in the dataset.\\n\"      \n             + str(table.shape[0]) + \" of these columns have missing variables.\")\n    return table\n\nvalues_table(data_missings) \n\n# 24.9% of customer information is missing. Customer information cannot be filled in any way. However, we can investigate the cause and effects of this missingness.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.Description.isnull()].CustomerID.isnull().value_counts(),data[data.Description.isnull()].UnitPrice.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Description_lower_case\"] = data[\"Description\"].str.lower()\ndata.Description_lower_case.dropna().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"Description_lower_case\"].str.contains(\"missing\", na=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"Description_lower_case\"].str.contains(\"[?]\", na=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"Description_lower_case\"].str.startswith(\"nan\", na=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data.Description_lower_case.isnull()==False, \"Description_lower_case\"] = data.loc[\n    data.Description_lower_case.isnull()==False, \"Description_lower_case\"\n].apply(lambda x: np.where(\"missing\" in x, None, x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"Description_lower_case\"].str.contains(\"missing\", na=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data.Description_lower_case.isnull()==False, \"Description_lower_case\"] = data.loc[\n    data.Description_lower_case.isnull()==False, \"Description_lower_case\"\n].apply(lambda x: np.where(\"?\" in x, None, x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"Description_lower_case\"].str.contains(\"[?]\", na=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= data.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(['Description'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['InvoiceDate'] = pd.to_datetime(df.InvoiceDate, format='%m/%d/%Y %H:%M')\ndf['CustomerID'] = df['CustomerID'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.insert(loc=2, column='Year', value=df.InvoiceDate.dt.year)\ndf.insert(loc=3, column='Month', value=df.InvoiceDate.dt.month)\ndf.insert(loc=4, column='Day', value=(df.InvoiceDate.dt.dayofweek)+1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grouping Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1=df.groupby(['Country'], as_index=False)[\"InvoiceNo\"].count()\ndf_1=df_1.sort_values(by='InvoiceNo', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.barplot(df_1.Country, df_1.InvoiceNo, alpha=0.8,palette=\"Blues_r\")\nplt.title('Number of Transactions in Countries')\nplt.ylabel('Number of Transactions', fontsize=12)\nplt.xlabel('Country', fontsize=12)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2=df.groupby(['Month','Year'], as_index=False)[\"InvoiceNo\"].count()\nplt.figure(figsize=(20,5))\nsns.barplot(df_2.Month, df_2.InvoiceNo,palette=\"PiYG_r\")\nplt.ylabel(\"Number of Transactions\")\nplt.title(\"The Number of Transactions by Months\")\nplt.xticks([0,1,2,3,4,5,6,7,8,9,10,11],['Jan-2010','Feb-2011','Mar-2011','Apr-2011','May-2011','Jun-2011','July-2011','Aug-2011','Sep-2011','Oct-2011','Nov-2011','Dec-2010']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_3=df.groupby(['Day'], as_index=False)[\"InvoiceNo\"].count()\nplt.figure(figsize=(20,5))\nsns.barplot(df_3.Day, df_3.InvoiceNo,palette=\"Spectral_r\")\nplt.ylabel(\"Number of Transactions\")\nplt.title(\"The Number of Transactions by Days\")\nplt.xticks([0,1,2,3,4,5,6],['Mon','Tue','Wed','Thu','Fri','Sat','Sun']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_4= df.groupby(['CustomerID', 'InvoiceNo'], as_index=False)['Quantity'].sum()\ndf_4=df_4.sort_values(by='CustomerID')\ndf_4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Canceled_orders'] = df['InvoiceNo'].apply(lambda x:int('C' in x))\ndf_5=pd.DataFrame([{'Customers': len(df['CustomerID'].value_counts()),\n               'Products': len(df['StockCode'].value_counts()),    \n               'Orders': (df['Canceled_orders'].values == 0).sum(),\n               'Canceled_orders' : (df['Canceled_orders'].values == 1).sum()}],index=['num.'])\ndf_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_6=df[df['Canceled_orders'] == 1].groupby(['CustomerID', 'InvoiceNo','Canceled_orders'],\n                                            as_index=False)['Quantity'].sum()\ndf_6.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TotalPrice'] = df['UnitPrice'] * df['Quantity'] \ndf_7= df.groupby(['CustomerID','InvoiceNo'], as_index=False)['TotalPrice'].sum()\ndf_7=df_7.sort_values(by='CustomerID')\ndf_7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_7=df[df.UnitPrice == 0].groupby(['CustomerID', 'StockCode','Description_lower_case'],\n                                            as_index=False)['Quantity'].sum()\ndf_7.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_7=df[df.UnitPrice == 0].groupby(['CustomerID', 'InvoiceNo','Description_lower_case'],\n                                            as_index=False)['Quantity'].sum()\ndf_7.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_8=df.groupby(\"StockCode\").Description_lower_case.nunique()\ndf_8=df_8.sort_values(ascending=False).to_frame()\ndisplay(df_8.loc[df_8.Description_lower_case >1 ].head());\ndisplay(df.loc[df.StockCode == \"23196\"\n              ].Description_lower_case.value_counts().to_frame());","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outlier Handling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_outliers=df.filter([ 'Quantity', 'UnitPrice', 'Canceled_orders', 'TotalPrice'],axis=1)\nplt.figure(figsize=(20,35))\nfor num,col in enumerate(df_outliers.columns,1):\n    plt.subplot(8, 5, num)\n    sns.boxplot(df_outliers[col])\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:, [\"Quantity\", \"UnitPrice\",\"TotalPrice\"]].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new=df.select_dtypes(include=['int', 'float'])\n\noutliers={}\nfor col in df_new:\n    lower_lim = df_new[col].quantile(q=0.01)\n    upper_lim = df_new[col].quantile(q=0.99)\n    outliers[col] =  len(df_new[col][(df_new[col] > upper_lim)| (df_new[col] < lower_lim)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_hardedge=pd.DataFrame(outliers.items(),columns=['Feature','Outliers'])\noutliers_hardedge ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Too many outliers detected.It would not be right to remove it from the data immediately\nbecause big data loss is not something we want. Let's try to visualize it as below."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pozitive= df.loc[df.TotalPrice > 0].copy()\nplt.figure(figsize=(18,5))\nsns.distplot(np.log(df_pozitive.TotalPrice), bins=15, kde=False, color=\"blue\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.exp(-2.5),np.exp(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,5))\nsns.distplot(np.log(df.Quantity), bins=10, kde=False, color=\"blue\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.exp(0),np.exp(6.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=df[\"Quantity\"].count()\nb=df[\"Quantity\"].loc[(df.Quantity <666 )].count()\nc=a-b\na,b,c #We can extract 234 of them from the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can drop 234 of the quantity from the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"m=df[\"TotalPrice\"].count()\nn=df[\"TotalPrice\"].loc[(df.TotalPrice >0.08) & (df.TotalPrice <2981 ) ].count()\nk=m-n\nm,n,k","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can drop 8963 of the total price from the data.Again, it means a high number of outliers, so we can drop according to the hard edge method. But it is useful to do it after seeing the reaction of the model."},{"metadata":{},"cell_type":"markdown","source":"# Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nheatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\n\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}